# .env.template

# =============================================================================
# OpenRouter Configuration (Primary LLM Provider) 
# =============================================================================
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# Model Configuration
DEFAULT_MODEL=anthropic/claude-3.5-sonnet
ROUTER_MODEL=deepseek/deepseek-chat
LOGIC_MODEL=anthropic/claude-3.5-sonnet
HUMAN_INTERFACE_MODEL=anthropic/claude-3.5-sonnet
# LLM Provider Configuration
PREFERRED_PROVIDER=openrouter  # "openrouter", "ollama", or "auto"
ENABLE_FALLBACK=true  # Fall back to other providers if preferred fails

# =============================================================================
# FastAPI Server Configuration
# =============================================================================
HOST=0.0.0.0
PORT=8000
ENVIRONMENT=development
DEBUG=true
RELOAD=true

# =============================================================================
# Future Phases Configuration
# =============================================================================

# Database
POSTGRES_URL=postgresql://postgres:password@localhost:5432/langchain_agent_hub

# OpenAI
OPENAI_API_KEY=your_openai_key_for_embeddings

# Ollama
OLLAMA_BASE_URL=http://localhost:11434
# Ollama Configuration
OLLAMA_ENABLED=true
OLLAMA_DEFAULT_MODEL=llama2
OLLAMA_TIMEOUT=30
OLLAMA_TEMPERATURE=0.7
OLLAMA_MAX_TOKENS=
OLLAMA_STREAMING=true
OLLAMA_HEALTH_CHECK_INTERVAL=60
OLLAMA_AUTO_HEALTH_CHECK=true

# SearXNG
SEARXNG_URL=http://localhost:8080

# Security
SECRET_KEY=your_secret_key_generate_a_long_random_string